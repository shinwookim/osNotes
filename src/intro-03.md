# History of the Operating System
## Early Days of Computing
Before the days of computers, the vast majority of computation (mathematical calculations) were done by **human calculators** who were often female manual laborers.

However, when World War II broke out, the military needed a way to break the encryption on secret messages. This required large amounts of complex calculations and led to the development of the first **mechanical computer**. As the war ended, **electronic (digital) computers** were developed. These early primitive computers were single-purpose computation machines which were not programmable.

After the war, the military took charge in developing electronic computers in national research labs. At those labs, academics saw the potential of using computers for research, and built systems which could be programmed (by manipulating physical wires).

By the 1950s, the **Von Neumann architecture** was proposed and computers which could execute code and manipulate data were being developed. These computers no longer required manipulating physical wires to program, but ran software that was written in machine language/code.

Soon, hardware became faster and programs, called **compilers**, were developed to encode a programming languages into machine code. As such, high-level programming languages were developed.

## Rise of Assembly Language(s)
In the 1970s, many CPU architectures and instruction sets were being proposed (and constantly changed) as researchers experimented to make computers even faster.

Most developers, during this, programmed in assembly language (as compiling code written in a high-level language was slow and took time away from the computer to do other work). However, the constantly changing instruction sets meant that the computers of these times were not compatible with each other.

### IBM standardizes the ISA
With various competing computer models which were not compatible with each other, many smaller institution were hesitant in adopting new computers which were quite expensive at the time. IBM saw this and realized they were missing out of potential customers and decided to create a set of three computers which shared the same fundamental architecture with varying performances. The three computers were compatible with each other and were easily swappable meaning smaller institutions could now afford computers and scale up as they needed to. Furthermore, these new computers drove efforts at standardization/compatibility, and the overall adoption of computers.

## Need for Multiprogramming and UNIX
The invention and development of the transistor quickly brought the miniaturization and a boost in performance for computers. By the 1970s, computers become fast enough that a single person running a single process at a time did not maximize the use of available resources.

This opened the door for multiprogramming and efforts to design a system which could efficiently run multiple programs simultaneously quickly took off. As a part of this effort, MIT researchers at Bell Labs began developing the first operating system which could support multiprogramming called **Multics**. Although this project brought many advancements in the field and praise from its users, it ultimately failed and the project was scrapped.

Yet, few programmers at Bell Labs were persistent about this goal (a multiprogramming system) and created a smaller, stripped-down version of Multics. They developed the **C language** for this project and called their final product **Unix**.

## Widespread Adoption of Computers
In the early 80s, the price of computers came down enough to allow for consumers to buy or build a personal computer at home.

### Proposed Proto-Internet
These early PCs, nonetheless, often lacked in performance and higher performance systems were still extremely expensive. Thus, some people proposed that institutions/government (with large enough funding) such as cities and towns should purchase a high performance machine and allow consumers to plug in a terminal at home for a fee (much like a utility).

Eventually, however, this proposal was not largely adopted. The hardware inside personal computers became much faster and much cheaper than anyone could predict and by the end of the decade, a paradigm shift occurred leading to the miniaturization and mass production of computers.

# Ontogeny Recapitulates Phylogeny
> *What's old is new again!*

Yet, this teaches us why we study history. Although the initial proposal for a network of shared computers did not take off, it would come back in the form of what we now know as the **Internet**. Studying history allows us to discover unrealized ideas that may be realized in the future. Computers often follow a similar cycle, and studying it allows us a better understanding of how they work.


